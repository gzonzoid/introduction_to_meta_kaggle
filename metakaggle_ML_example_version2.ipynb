{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Kaggle ML example\n",
    "\n",
    "Goal: predict user ranking from\n",
    " - first and last submission date\n",
    "\n",
    "Features to add:\n",
    " - number of submissions made to the contest\n",
    " - number of team members\n",
    " - number of contests participated in (by leader or whole team?)\n",
    " - length of team name\n",
    "\n",
    "Other things to add:\n",
    " - improve prediction: instead of raw ranking normalize by total number after dropping inactives (single submissions?), try predicting medaled or not (too imbalanced?)\n",
    " - drop dublicates\n",
    " \n",
    "Currently it always predicts the same thing... That is not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sklearn.ensemble as ske\n",
    "import meta_kaggle_utils as utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'meta-kaggle/'\n",
    "submission_file_name = 'Submissions.csv'\n",
    "team_file_name = 'Teams.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load submissions and teams files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laseaman/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3214: DtypeWarning: Columns (5,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n",
      "/Users/laseaman/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 4837705 rows.\n",
      "The table contains the following columns: \n",
      "['SubmittedUserId' 'TeamId' 'SourceKernelVersionId' 'SubmissionDate'\n",
      " 'ScoreDate' 'IsAfterDeadline' 'PublicScoreLeaderboardDisplay'\n",
      " 'PublicScoreFullPrecision' 'PrivateScoreLeaderboardDisplay'\n",
      " 'PrivateScoreFullPrecision']\n"
     ]
    }
   ],
   "source": [
    "# load the submission file\n",
    "submissions = utils.load_kaggle_csv(data_location + submission_file_name)\n",
    "# convert scores to numeric values\n",
    "submissions['PublicScoreFullPrecision'] = pd.to_numeric(submissions['PublicScoreFullPrecision'], errors='coerce')\n",
    "submissions['PrivateScoreFullPrecision'] = pd.to_numeric(submissions['PrivateScoreFullPrecision'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laseaman/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3214: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 1656073 rows.\n",
      "The table contains the following columns: \n",
      "['CompetitionId' 'TeamLeaderId' 'TeamName' 'ScoreFirstSubmittedDate'\n",
      " 'LastSubmissionDate' 'PublicLeaderboardSubmissionId'\n",
      " 'PrivateLeaderboardSubmissionId' 'IsBenchmark' 'Medal' 'MedalAwardDate'\n",
      " 'PublicLeaderboardRank' 'PrivateLeaderboardRank']\n"
     ]
    }
   ],
   "source": [
    "# load the teams file\n",
    "teams = utils.load_kaggle_csv(data_location + team_file_name)\n",
    "# drop teams that never submitted anything\n",
    "teams = teams.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dates before and after conversion to timestamps: \n",
      "<class 'str'>\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# convert dates to datetime objects\n",
    "print('type of dates before and after conversion to timestamps: ')\n",
    "print(type(teams.ScoreFirstSubmittedDate[497]))\n",
    "teams.ScoreFirstSubmittedDate = pd.to_datetime(teams.ScoreFirstSubmittedDate)\n",
    "print(type(teams.ScoreFirstSubmittedDate[497]))\n",
    "\n",
    "# repeate with last date\n",
    "teams.LastSubmissionDate = pd.to_datetime(teams.LastSubmissionDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_day(dates):\n",
    "    \"\"\" calculate a numeric value for a pandas series of dates\"\"\"\n",
    "    dayofyear = dates.dt.dayofyear\n",
    "    year = dates.dt.year\n",
    "\n",
    "    # subtract off the first year and calculate the days\n",
    "    year = year - min(year)\n",
    "    day = dayofyear + year * 365\n",
    "    return day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates as timestamps:\n",
      "Id\n",
      "497   2010-04-30\n",
      "500   2010-05-02\n",
      "503   2010-05-05\n",
      "504   2010-05-11\n",
      "505   2010-05-19\n",
      "Name: ScoreFirstSubmittedDate, dtype: datetime64[ns]\n",
      "dates as numbers:\n",
      "Id\n",
      "497    120\n",
      "500    122\n",
      "503    125\n",
      "504    131\n",
      "505    139\n",
      "Name: ScoreFirstSubmittedDate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert date to a number of days after Jan 1st of the first year of data in the dataset\n",
    "days = date_to_day(teams.ScoreFirstSubmittedDate)\n",
    "teams['first_date_as_day'] = days\n",
    "\n",
    "print('dates as timestamps:')\n",
    "print(teams.ScoreFirstSubmittedDate[0:5])\n",
    "print('dates as numbers:')\n",
    "print(days[0:5])\n",
    "\n",
    "# repeate for the last date\n",
    "teams['last_date_as_day'] = date_to_day(teams.LastSubmissionDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teams matrix shape:  (22234, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompetitionId</th>\n",
       "      <th>TeamLeaderId</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>ScoreFirstSubmittedDate</th>\n",
       "      <th>LastSubmissionDate</th>\n",
       "      <th>PublicLeaderboardSubmissionId</th>\n",
       "      <th>PrivateLeaderboardSubmissionId</th>\n",
       "      <th>IsBenchmark</th>\n",
       "      <th>Medal</th>\n",
       "      <th>MedalAwardDate</th>\n",
       "      <th>PublicLeaderboardRank</th>\n",
       "      <th>PrivateLeaderboardRank</th>\n",
       "      <th>first_date_as_day</th>\n",
       "      <th>last_date_as_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2435</td>\n",
       "      <td>619.0</td>\n",
       "      <td>jonp</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2435</td>\n",
       "      <td>673.0</td>\n",
       "      <td>Thylacoleo</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>2010-07-10</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>122</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2435</td>\n",
       "      <td>672.0</td>\n",
       "      <td>Fontanelles</td>\n",
       "      <td>2010-05-05</td>\n",
       "      <td>2010-05-08</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2435</td>\n",
       "      <td>727.0</td>\n",
       "      <td>IFM_bioinformatics</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>2010-05-12</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2435</td>\n",
       "      <td>728.0</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CompetitionId  TeamLeaderId            TeamName ScoreFirstSubmittedDate  \\\n",
       "Id                                                                             \n",
       "497           2435         619.0                jonp              2010-04-30   \n",
       "500           2435         673.0          Thylacoleo              2010-05-02   \n",
       "503           2435         672.0         Fontanelles              2010-05-05   \n",
       "504           2435         727.0  IFM_bioinformatics              2010-05-11   \n",
       "505           2435         728.0           Amsterdam              2010-05-19   \n",
       "\n",
       "    LastSubmissionDate  PublicLeaderboardSubmissionId  \\\n",
       "Id                                                      \n",
       "497         2010-04-30                         2182.0   \n",
       "500         2010-07-10                         2187.0   \n",
       "503         2010-05-08                         2199.0   \n",
       "504         2010-05-12                         2203.0   \n",
       "505         2010-05-19                         2306.0   \n",
       "\n",
       "     PrivateLeaderboardSubmissionId  IsBenchmark  Medal MedalAwardDate  \\\n",
       "Id                                                                       \n",
       "497                          2182.0        False    3.0     07/15/2016   \n",
       "500                          2187.0        False    3.0     07/15/2016   \n",
       "503                          2199.0        False    3.0     07/15/2016   \n",
       "504                          2246.0        False    1.0     07/15/2016   \n",
       "505                          2308.0        False    2.0     07/15/2016   \n",
       "\n",
       "     PublicLeaderboardRank  PrivateLeaderboardRank  first_date_as_day  \\\n",
       "Id                                                                      \n",
       "497                   41.0                    25.0                120   \n",
       "500                   31.0                    23.0                122   \n",
       "503                    6.0                    31.0                125   \n",
       "504                   13.0                     9.0                131   \n",
       "505                   18.0                    11.0                139   \n",
       "\n",
       "     last_date_as_day  \n",
       "Id                     \n",
       "497               120  \n",
       "500               191  \n",
       "503               128  \n",
       "504               132  \n",
       "505               139  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('teams matrix shape: ', teams.shape)\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge submission and teams files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a joining column to the submissions matrix\n",
    "submissions['join_teams_submissions'] = submissions.index\n",
    "submissions['PublicLeaderboardScore'] = submissions.PublicScoreFullPrecision\n",
    "submissions['PrivateLeaderboardScore'] = submissions.PrivateScoreFullPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the column to add (and keep column created for the join)\n",
    "public_leaderboard = submissions[['join_teams_submissions', 'PublicLeaderboardScore']]\n",
    "private_leaderboard = submissions[['join_teams_submissions', 'PrivateLeaderboardScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column with the same name in the teams matrix\n",
    "teams['join_teams_submissions'] = teams.PublicLeaderboardSubmissionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the team, public_leaderboard, and new teams_with_score data frames:\n",
      "(22234, 15) (4837705, 2) (22234, 19)\n",
      "shape of teams_with_score matrix after dropping redundant columns: \n",
      "(22234, 16)\n"
     ]
    }
   ],
   "source": [
    "# perform the merge\n",
    "teams_with_score = teams.join(public_leaderboard, on='join_teams_submissions', rsuffix='_j1')\n",
    "teams_with_score = teams_with_score.join(private_leaderboard, on='join_teams_submissions', rsuffix='_j2')\n",
    "print('shape of the team, public_leaderboard, and new teams_with_score data frames:')\n",
    "print(teams.shape, public_leaderboard.shape, teams_with_score.shape)\n",
    "\n",
    "# drop the columns added for joining\n",
    "drop_cols = ['join_teams_submissions_j1', 'join_teams_submissions_j2', 'join_teams_submissions']\n",
    "teams_with_score = teams_with_score.drop(drop_cols, axis=1)\n",
    "print('shape of teams_with_score matrix after dropping redundant columns: ')\n",
    "print(teams_with_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up the matrix for the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns available for use: \n",
      "['CompetitionId' 'TeamLeaderId' 'TeamName' 'ScoreFirstSubmittedDate'\n",
      " 'LastSubmissionDate' 'PublicLeaderboardSubmissionId'\n",
      " 'PrivateLeaderboardSubmissionId' 'IsBenchmark' 'Medal' 'MedalAwardDate'\n",
      " 'PublicLeaderboardRank' 'PrivateLeaderboardRank' 'first_date_as_day'\n",
      " 'last_date_as_day' 'PublicLeaderboardScore' 'PrivateLeaderboardScore']\n"
     ]
    }
   ],
   "source": [
    "print('columns available for use: ')\n",
    "print(teams_with_score.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected feature column: PrivateLeaderboardRank\n",
      "(22234, 3) shape of feature matrix\n",
      "22234 length of predictions\n",
      "Two of the numbers above should be the same.\n"
     ]
    }
   ],
   "source": [
    "# select feature column. Must be in the list above\n",
    "predict_col = 'PrivateLeaderboardRank'\n",
    "print('selected feature column: ' + predict_col)\n",
    "\n",
    "# select fetture columns to use. These must be selected from the list above\n",
    "feature_cols = ['CompetitionId', 'first_date_as_day', 'last_date_as_day']\n",
    "feature_matrix = teams_with_score[feature_cols]\n",
    "\n",
    "# make sure things are the right shapes\n",
    "print(feature_matrix.shape, 'shape of feature matrix')\n",
    "prediction = teams_with_score[predict_col]\n",
    "print(len(prediction), 'length of predictions')\n",
    "print('Two of the numbers above should be the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix shape before and after droping missing values\n",
      "(22234, 3)\n",
      "(22234, 3)\n"
     ]
    }
   ],
   "source": [
    "# TODO: FIX THIS - CURRENTLY IF ANYTHING IS DROPPED IT WILL BREAK because it is not also dropping from the \n",
    "#   predictions so they won't be the same length.\n",
    "\n",
    "\n",
    "# nan's will break the regression, so drop them\n",
    "print('feature matrix shape before and after droping missing values')\n",
    "# If it gets much smaller, something is not working well. You might need to impute \n",
    "#   missing values (or look for a bug in your code)\n",
    "print(feature_matrix.shape)\n",
    "feature_matrix = feature_matrix.dropna(how='any')\n",
    "print(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of feature matrix:\n",
      "     CompetitionId  first_date_as_day  last_date_as_day\n",
      "Id                                                     \n",
      "497           2435                120               120\n",
      "500           2435                122               191\n",
      "503           2435                125               128\n",
      "504           2435                131               132\n",
      "505           2435                139               139\n",
      "start of prediction matrix\n",
      "Id\n",
      "497    25.0\n",
      "500    23.0\n",
      "503    31.0\n",
      "504     9.0\n",
      "505    11.0\n",
      "Name: PrivateLeaderboardRank, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('start of feature matrix:')\n",
    "print(feature_matrix.head())\n",
    "print('start of prediction matrix')\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a random forest regression\n",
    "regr = ske.RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100)\n",
    "regr.fit(feature_matrix, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and their importance\n",
      "['CompetitionId' 'first_date_as_day' 'last_date_as_day']\n",
      "[0.99238626 0.00344092 0.00417282]\n",
      "prediction for [2435, 130, 132]\n",
      "[46.23803527]\n",
      "prediction for [2435, 140, 250]\n",
      "[46.23803527]\n",
      "prediction for [4495, 130, 132]\n",
      "[81.42070571]\n"
     ]
    }
   ],
   "source": [
    "print('features and their importance')\n",
    "print(feature_matrix.columns.values)\n",
    "print(regr.feature_importances_)\n",
    "\n",
    "a = [2435, 130, 132]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))\n",
    "a = [2435, 140, 250]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))\n",
    "a = [4495, 130, 132]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model for the single largest competition\n",
    "It should be an easier problem if all of the data is from the same competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7082    515\n",
      "4986    512\n",
      "8076    455\n",
      "6565    383\n",
      "6649    377\n",
      "Name: CompetitionId, dtype: int64\n",
      "7082\n"
     ]
    }
   ],
   "source": [
    "# find the most common competition\n",
    "num_occur = feature_matrix.CompetitionId.value_counts()\n",
    "print(num_occur.iloc[0:5])\n",
    "competition_use = num_occur.index.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(515, 2) shape of feature matrix\n",
      "515 length of predictions\n",
      "Two of the numbers above should be the same.\n"
     ]
    }
   ],
   "source": [
    "# select the data from that commetition\n",
    "features_competition = feature_matrix[feature_matrix.CompetitionId == competition_use]\n",
    "features_competition = features_competition.drop('CompetitionId', axis=1)\n",
    "predict_competition = prediction[feature_matrix.CompetitionId == competition_use]\n",
    "\n",
    "# make sure things are the right shapes\n",
    "print(features_competition.shape, 'shape of feature matrix')\n",
    "print(len(predict_competition), 'length of predictions')\n",
    "print('Two of the numbers above should be the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a random forest regression\n",
    "regr2 = ske.RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100)\n",
    "regr2.fit(features_competition, predict_competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features and their importance\n",
      "['first_date_as_day' 'last_date_as_day']\n",
      "[0.58257537 0.41742463]\n",
      "prediction for [2888, 2889]\n",
      "[231.44241639]\n",
      "prediction for [2888, 2905]\n",
      "[231.44241639]\n",
      "prediction for [2950, 2982]\n",
      "[231.44241639]\n"
     ]
    }
   ],
   "source": [
    "# look at the results\n",
    "print('features and their importance')\n",
    "print(features_competition.columns.values)\n",
    "print(regr2.feature_importances_)\n",
    "\n",
    "a = [2888, 2889]\n",
    "print('prediction for', a)\n",
    "print(regr2.predict([a]))\n",
    "a = [2888, 2905]\n",
    "print('prediction for', a)\n",
    "print(regr2.predict([a]))\n",
    "a = [2950, 2982]\n",
    "print('prediction for', a)\n",
    "print(regr2.predict([a]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        first_date_as_day  last_date_as_day\n",
      "Id                                         \n",
      "953151               2883              2888\n",
      "953171               2888              2888\n",
      "953176               2888              2888\n",
      "953179               2887              2887\n",
      "953184               2888              2888\n",
      "953190               2885              2888\n",
      "953217               2888              2888\n",
      "953260               2884              2884\n",
      "953303               2888              2888\n",
      "953351               2888              2888\n",
      "         first_date_as_day  last_date_as_day\n",
      "Id                                          \n",
      "1120859               2887              2888\n",
      "1121170               2888              2888\n",
      "1121904               2888              2888\n",
      "1121907               2885              2885\n",
      "1122260               2885              2886\n",
      "1122497               2888              2888\n",
      "1123362               2888              2888\n",
      "1123509               2888              2888\n",
      "1125527               2888              2888\n",
      "1139013               2887              2887\n"
     ]
    }
   ],
   "source": [
    "print(features_competition.iloc[0:10])\n",
    "print(features_competition.iloc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features\n",
    "I would like to add \n",
    "- the number of submissions\n",
    "- the number of teammembers\n",
    "- length of team name\n",
    "- number of contests participated in (by leader or whole team?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
