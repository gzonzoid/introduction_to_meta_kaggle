{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Kaggle ML example\n",
    "\n",
    "Goal: predict user ranking from\n",
    " - first and last submission date\n",
    "\n",
    "Features to add:\n",
    " - number of submissions made to the contest\n",
    " - number of team members\n",
    " - number of contests participated in (by leader or whole team?)\n",
    " - length of team name\n",
    "\n",
    "Other things to add:\n",
    " - improve prediction: instead of raw ranking normalize by total number after dropping inactives (single submissions?), try predicting medaled or not (too imbalanced?)\n",
    " - drop dublicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_day(dates):\n",
    "    \"\"\" calculate a numeric value for a pandas series of dates\"\"\"\n",
    "    dayofyear = dates.dt.dayofyear\n",
    "    year = dates.dt.year\n",
    "\n",
    "    # subtract off the first year and calculate the days\n",
    "    year = year - min(year)\n",
    "    day = dayofyear + year * 365\n",
    "    return day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_drop(feature, predict):\n",
    "    # combine dataframes\n",
    "    tmp_features = pd.concat([feature, predict], axis=1)\n",
    "    # drop missing values\n",
    "    tmp_features = tmp_features.dropna(how='any')\n",
    "    # drop duplicate rows\n",
    "    tmp_features = tmp_features.drop_duplicates()\n",
    "    # reseparate features from prediction values\n",
    "    final_predict = tmp_features.iloc[:,-1]\n",
    "    final_feature = tmp_features.iloc[:,0:-1]\n",
    "    return final_feature, final_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import sklearn.ensemble as ske\n",
    "import meta_kaggle_utils as utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'meta-kaggle/'\n",
    "submission_file_name = 'Submissions.csv'\n",
    "team_file_name = 'Teams.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load submissions and teams files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2903: DtypeWarning: Columns (5,7,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 5015235 rows.\n",
      "The table contains the following columns: \n",
      "['SubmittedUserId' 'TeamId' 'SourceKernelVersionId' 'SubmissionDate'\n",
      " 'ScoreDate' 'IsAfterDeadline' 'PublicScoreLeaderboardDisplay'\n",
      " 'PublicScoreFullPrecision' 'PrivateScoreLeaderboardDisplay'\n",
      " 'PrivateScoreFullPrecision']\n"
     ]
    }
   ],
   "source": [
    "# load the submission file\n",
    "submissions = utils.load_kaggle_csv(data_location + submission_file_name)\n",
    "# convert scores to numeric values\n",
    "submissions['PublicScoreFullPrecision'] = pd.to_numeric(submissions['PublicScoreFullPrecision'], errors='coerce')\n",
    "submissions['PrivateScoreFullPrecision'] = pd.to_numeric(submissions['PrivateScoreFullPrecision'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file contains 1740398 rows.\n",
      "The table contains the following columns: \n",
      "['CompetitionId' 'TeamLeaderId' 'TeamName' 'ScoreFirstSubmittedDate'\n",
      " 'LastSubmissionDate' 'PublicLeaderboardSubmissionId'\n",
      " 'PrivateLeaderboardSubmissionId' 'IsBenchmark' 'Medal' 'MedalAwardDate'\n",
      " 'PublicLeaderboardRank' 'PrivateLeaderboardRank']\n"
     ]
    }
   ],
   "source": [
    "# load the teams file\n",
    "teams = utils.load_kaggle_csv(data_location + team_file_name)\n",
    "# drop teams that never submitted anything\n",
    "teams = teams.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dates before and after conversion to timestamps: \n",
      "<class 'str'>\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "# convert dates to datetime objects\n",
    "print('type of dates before and after conversion to timestamps: ')\n",
    "print(type(teams.ScoreFirstSubmittedDate[497]))\n",
    "teams.ScoreFirstSubmittedDate = pd.to_datetime(teams.ScoreFirstSubmittedDate)\n",
    "print(type(teams.ScoreFirstSubmittedDate[497]))\n",
    "\n",
    "# repeate with last date\n",
    "teams.LastSubmissionDate = pd.to_datetime(teams.LastSubmissionDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates as timestamps:\n",
      "Id\n",
      "497   2010-04-30\n",
      "500   2010-05-02\n",
      "503   2010-05-05\n",
      "504   2010-05-11\n",
      "505   2010-05-19\n",
      "Name: ScoreFirstSubmittedDate, dtype: datetime64[ns]\n",
      "dates as numbers:\n",
      "Id\n",
      "497    120\n",
      "500    122\n",
      "503    125\n",
      "504    131\n",
      "505    139\n",
      "Name: ScoreFirstSubmittedDate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert date to a number of days after Jan 1st of the first year of data in the dataset\n",
    "days = date_to_day(teams.ScoreFirstSubmittedDate)\n",
    "teams['first_date_as_day'] = days\n",
    "\n",
    "print('dates as timestamps:')\n",
    "print(teams.ScoreFirstSubmittedDate[0:5])\n",
    "print('dates as numbers:')\n",
    "print(days[0:5])\n",
    "\n",
    "# repeate for the last date\n",
    "teams['last_date_as_day'] = date_to_day(teams.LastSubmissionDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teams matrix shape:  (22234, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompetitionId</th>\n",
       "      <th>TeamLeaderId</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>ScoreFirstSubmittedDate</th>\n",
       "      <th>LastSubmissionDate</th>\n",
       "      <th>PublicLeaderboardSubmissionId</th>\n",
       "      <th>PrivateLeaderboardSubmissionId</th>\n",
       "      <th>IsBenchmark</th>\n",
       "      <th>Medal</th>\n",
       "      <th>MedalAwardDate</th>\n",
       "      <th>PublicLeaderboardRank</th>\n",
       "      <th>PrivateLeaderboardRank</th>\n",
       "      <th>first_date_as_day</th>\n",
       "      <th>last_date_as_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2435</td>\n",
       "      <td>619.0</td>\n",
       "      <td>jonp</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>41.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2435</td>\n",
       "      <td>673.0</td>\n",
       "      <td>Thylacoleo</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>2010-07-10</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>122</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2435</td>\n",
       "      <td>672.0</td>\n",
       "      <td>Fontanelles</td>\n",
       "      <td>2010-05-05</td>\n",
       "      <td>2010-05-08</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>2199.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2435</td>\n",
       "      <td>727.0</td>\n",
       "      <td>IFM_bioinformatics</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>2010-05-12</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>2246.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2435</td>\n",
       "      <td>728.0</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>07/15/2016</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>139</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CompetitionId  TeamLeaderId            TeamName ScoreFirstSubmittedDate  \\\n",
       "Id                                                                             \n",
       "497           2435         619.0                jonp              2010-04-30   \n",
       "500           2435         673.0          Thylacoleo              2010-05-02   \n",
       "503           2435         672.0         Fontanelles              2010-05-05   \n",
       "504           2435         727.0  IFM_bioinformatics              2010-05-11   \n",
       "505           2435         728.0           Amsterdam              2010-05-19   \n",
       "\n",
       "    LastSubmissionDate  PublicLeaderboardSubmissionId  \\\n",
       "Id                                                      \n",
       "497         2010-04-30                         2182.0   \n",
       "500         2010-07-10                         2187.0   \n",
       "503         2010-05-08                         2199.0   \n",
       "504         2010-05-12                         2203.0   \n",
       "505         2010-05-19                         2306.0   \n",
       "\n",
       "     PrivateLeaderboardSubmissionId  IsBenchmark  Medal MedalAwardDate  \\\n",
       "Id                                                                       \n",
       "497                          2182.0        False    3.0     07/15/2016   \n",
       "500                          2187.0        False    3.0     07/15/2016   \n",
       "503                          2199.0        False    3.0     07/15/2016   \n",
       "504                          2246.0        False    1.0     07/15/2016   \n",
       "505                          2308.0        False    2.0     07/15/2016   \n",
       "\n",
       "     PublicLeaderboardRank  PrivateLeaderboardRank  first_date_as_day  \\\n",
       "Id                                                                      \n",
       "497                   41.0                    25.0                120   \n",
       "500                   31.0                    23.0                122   \n",
       "503                    6.0                    31.0                125   \n",
       "504                   13.0                     9.0                131   \n",
       "505                   18.0                    11.0                139   \n",
       "\n",
       "     last_date_as_day  \n",
       "Id                     \n",
       "497               120  \n",
       "500               191  \n",
       "503               128  \n",
       "504               132  \n",
       "505               139  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('teams matrix shape: ', teams.shape)\n",
    "teams.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge submission and teams files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a joining column to the submissions matrix\n",
    "submissions['join_teams_submissions'] = submissions.index\n",
    "submissions['PublicLeaderboardScore'] = submissions.PublicScoreFullPrecision\n",
    "submissions['PrivateLeaderboardScore'] = submissions.PrivateScoreFullPrecision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the column to add (and keep column created for the join)\n",
    "public_leaderboard = submissions[['join_teams_submissions', 'PublicLeaderboardScore']]\n",
    "private_leaderboard = submissions[['join_teams_submissions', 'PrivateLeaderboardScore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column with the same name in the teams matrix\n",
    "teams['join_teams_submissions'] = teams.PublicLeaderboardSubmissionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the team, public_leaderboard, and new teams_with_score data frames:\n",
      "(22234, 15) (5015235, 2) (22234, 19)\n",
      "shape of teams_with_score matrix after dropping redundant columns: \n",
      "(22234, 16)\n"
     ]
    }
   ],
   "source": [
    "# perform the merge\n",
    "teams_with_score = teams.join(public_leaderboard, on='join_teams_submissions', rsuffix='_j1')\n",
    "teams_with_score = teams_with_score.join(private_leaderboard, on='join_teams_submissions', rsuffix='_j2')\n",
    "print('shape of the team, public_leaderboard, and new teams_with_score data frames:')\n",
    "print(teams.shape, public_leaderboard.shape, teams_with_score.shape)\n",
    "\n",
    "# drop the columns added for joining\n",
    "drop_cols = ['join_teams_submissions_j1', 'join_teams_submissions_j2', 'join_teams_submissions']\n",
    "teams_with_score = teams_with_score.drop(drop_cols, axis=1)\n",
    "print('shape of teams_with_score matrix after dropping redundant columns: ')\n",
    "print(teams_with_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set up the matrix for the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns available for use: \n",
      "['CompetitionId' 'TeamLeaderId' 'TeamName' 'ScoreFirstSubmittedDate'\n",
      " 'LastSubmissionDate' 'PublicLeaderboardSubmissionId'\n",
      " 'PrivateLeaderboardSubmissionId' 'IsBenchmark' 'Medal' 'MedalAwardDate'\n",
      " 'PublicLeaderboardRank' 'PrivateLeaderboardRank' 'first_date_as_day'\n",
      " 'last_date_as_day' 'PublicLeaderboardScore' 'PrivateLeaderboardScore']\n"
     ]
    }
   ],
   "source": [
    "print('columns available for use: ')\n",
    "print(teams_with_score.columns.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected feature column: PrivateLeaderboardRank\n"
     ]
    }
   ],
   "source": [
    "# select feature column. Must be in the list above\n",
    "predict_col = 'PrivateLeaderboardRank'\n",
    "print('selected feature column: ' + predict_col)\n",
    "\n",
    "# select fetture columns to use. These must be selected from the list above\n",
    "feature_cols = ['CompetitionId', 'first_date_as_day', 'last_date_as_day']\n",
    "\n",
    "# actually select the things\n",
    "feature_matrix = teams_with_score[feature_cols]\n",
    "prediction = teams_with_score[predict_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature matrix shape before and after droping missing values\n",
      "(22234, 3) (22234,)\n",
      "(22234, 3) (22234,)\n"
     ]
    }
   ],
   "source": [
    "# drop missing values & duplicates\n",
    "print('feature matrix shape before and after droping missing values')\n",
    "# If it gets much smaller, something is not working well. You might need to impute \n",
    "#   missing values (or look for a bug in your code)\n",
    "print(feature_matrix.shape, prediction.shape)\n",
    "feature_matrix, prediction = ml_drop(feature_matrix, prediction)\n",
    "print(feature_matrix.shape, prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of feature matrix:\n",
      "     CompetitionId  first_date_as_day  last_date_as_day\n",
      "Id                                                     \n",
      "497           2435                120               120\n",
      "500           2435                122               191\n",
      "503           2435                125               128\n",
      "504           2435                131               132\n",
      "505           2435                139               139\n",
      "start of prediction matrix\n",
      "Id\n",
      "497    25.0\n",
      "500    23.0\n",
      "503    31.0\n",
      "504     9.0\n",
      "505    11.0\n",
      "Name: PrivateLeaderboardRank, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('start of feature matrix:')\n",
    "print(feature_matrix.head())\n",
    "print('start of prediction matrix')\n",
    "print(prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22234, 3) shape of feature matrix\n",
      "22234 length of predictions\n",
      "Two of the numbers above should be the same.\n"
     ]
    }
   ],
   "source": [
    "# make sure things are the right shapes\n",
    "print(feature_matrix.shape, 'shape of feature matrix')\n",
    "print(len(prediction), 'length of predictions')\n",
    "print('Two of the numbers above should be the same.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=True, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a random forest regression\n",
    "regr = ske.RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100, oob_score=True)\n",
    "regr.fit(feature_matrix, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21514882643326927 oob score\n",
      "features and their importance\n",
      "['CompetitionId' 'first_date_as_day' 'last_date_as_day']\n",
      "[0.99238626 0.00344092 0.00417282]\n",
      "prediction for [2435, 130, 132]\n",
      "[46.23803527]\n",
      "prediction for [2435, 140, 250]\n",
      "[46.23803527]\n",
      "prediction for [4495, 130, 132]\n",
      "[81.42070571]\n"
     ]
    }
   ],
   "source": [
    "print(regr.oob_score_, 'oob score')\n",
    "\n",
    "print('features and their importance')\n",
    "print(feature_matrix.columns.values)\n",
    "print(regr.feature_importances_)\n",
    "\n",
    "a = [2435, 130, 132]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))\n",
    "a = [2435, 140, 250]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))\n",
    "a = [4495, 130, 132]\n",
    "print('prediction for', a)\n",
    "print(regr.predict([a]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model for the single largest competition\n",
    "It should be an easier problem if all of the data is from the same competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7082    515\n",
      "4986    512\n",
      "8076    455\n",
      "6565    383\n",
      "6649    377\n",
      "Name: CompetitionId, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find the most common competition\n",
    "num_occur = feature_matrix.CompetitionId.value_counts()\n",
    "print(num_occur.iloc[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competition_use = num_occur.index.values[0]\n",
    "competition_use = 8076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 2) shape of feature matrix\n",
      "455 length of predictions\n",
      "Two of the numbers above should be the same.\n"
     ]
    }
   ],
   "source": [
    "# select the data from that commetition\n",
    "features_competition = feature_matrix[feature_matrix.CompetitionId == competition_use]\n",
    "features_competition = features_competition.drop('CompetitionId', axis=1)\n",
    "predict_competition = prediction[feature_matrix.CompetitionId == competition_use]\n",
    "\n",
    "# make sure things are the right shapes\n",
    "print(features_competition.shape, 'shape of feature matrix')\n",
    "print(len(predict_competition), 'length of predictions')\n",
    "print('Two of the numbers above should be the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=True, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run a random forest regression\n",
    "regr2 = ske.RandomForestRegressor(max_depth=2, random_state=0,\n",
    "                             n_estimators=100, oob_score=True)\n",
    "regr2.fit(features_competition, predict_competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11432880755645802 oob score\n",
      "features and their importance\n",
      "['first_date_as_day' 'last_date_as_day']\n",
      "[0.69427318 0.30572682]\n",
      "prediction for [2990, 2992]\n",
      "[377.36903613]\n",
      "prediction for [3000, 3010]\n",
      "[201.27519959]\n"
     ]
    }
   ],
   "source": [
    "## look at the results\n",
    "print(regr2.oob_score_, 'oob score')\n",
    "\n",
    "print('features and their importance')\n",
    "print(features_competition.columns.values)\n",
    "print(regr2.feature_importances_)\n",
    "\n",
    "a = [2990, 2992]\n",
    "print('prediction for', a)\n",
    "print(regr2.predict([a]))\n",
    "a = [3000, 3010]\n",
    "print('prediction for', a)\n",
    "print(regr2.predict([a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         first_date_as_day  last_date_as_day\n",
      "Id                                          \n",
      "1203839               2999              2999\n",
      "1203843               2999              2999\n",
      "1203979               2996              2996\n",
      "1204014               2990              2999\n",
      "1204025               2999              2999\n",
      "1204071               2999              2999\n",
      "1204105               2999              2999\n",
      "1204139               2998              2999\n",
      "1204210               2999              2999\n",
      "1204311               2999              2999\n",
      "         first_date_as_day  last_date_as_day\n",
      "Id                                          \n",
      "1472468               2998              2998\n",
      "1472591               2999              2999\n",
      "1472820               2998              2998\n",
      "1473546               2999              2999\n",
      "1473636               2992              2992\n",
      "1473656               2998              2999\n",
      "1473687               2999              2999\n",
      "1473741               2992              2992\n",
      "1474673               2995              2995\n",
      "1475819               2999              2999\n"
     ]
    }
   ],
   "source": [
    "# used to figure out what reasonable values are for new predictions\n",
    "print(features_competition.iloc[0:10])\n",
    "print(features_competition.iloc[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features\n",
    "I would like to add \n",
    "- the number of submissions\n",
    "- the number of teammembers\n",
    "- length of team name\n",
    "- number of contests participated in (by leader or whole team?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
